import os
import torch
import nibabel as nib
import numpy as np
from tqdm import tqdm
from joblib import Parallel, delayed
from monai.data import MetaTensor
from monai.transforms import (
    Orientation,
    EnsureType,
)
from skimage.transform import resize

class CBCTPreprocessor:
    def __init__(
        self,
        root_dir: str,
        save_dir: str = "../ToothFairy_Training_Data",
        target_size: tuple = (160, 320, 320),  # Segformer3Dè¾“å…¥å°ºå¯¸
        crop_margin: int = 16                   # åŠ¨æ€è£å‰ªè¾¹ç•Œ
    ):
        """
        ç‰™é½¿CBCTé¢„å¤„ç†ç®¡é“
        root_dir: åŸå§‹æ•°æ®ç›®å½•ç»“æ„
            â”œâ”€â”€ imageTr
            â”‚   â””â”€â”€ case1.nii.gz
            â”‚   â””â”€â”€ case2.nii.gz
            â””â”€â”€ labelsTr
                â””â”€â”€ case1.nii.gz
                â””â”€â”€ case2.nii.gz
        """
        self.image_dir = os.path.join(root_dir, "imageTr")
        self.label_dir = os.path.join(root_dir, "labelsTr")
        self.save_dir = save_dir
        self.target_size = target_size
        self.crop_margin = crop_margin
        
        # è·å–æ‰€æœ‰ç—…ä¾‹ID
        self.case_ids = [f.split('.')[0] for f in os.listdir(self.image_dir) 
                        if f.endswith(('.nii', '.nii.gz'))]

    def __len__(self):
        return len(self.case_ids)

    def _load_volume(self, case_id):
        """åŠ è½½CBCTå›¾åƒ"""
        img_path = os.path.join(self.image_dir, f"{case_id}.nii.gz")
        img = nib.load(img_path)
        return img.get_fdata(), img.affine

    def _load_label(self, case_id):
        """åŠ è½½åˆ†å‰²æ ‡ç­¾"""
        label_path = os.path.join(self.label_dir, f"{case_id}.nii.gz")
        label = nib.load(label_path).get_fdata()
        return label.astype(np.uint8)

    def _ct_normalization(self, volume):
        """CBCTä¸“ç”¨æ ‡å‡†åŒ–ï¼ˆåŸºäºHounsfieldå•ä½ï¼‰"""
        # ç‰™é½¿CTå…¸å‹å€¼èŒƒå›´
        volume = np.clip(volume, -1000, 3000)  # å»é™¤å¼‚å¸¸å€¼
        volume = (volume + 1000) / 4000        # å½’ä¸€åŒ–åˆ°[0,1]
        return volume

    def _dynamic_crop(self, volume):
        """è‡ªåŠ¨è£å‰ªæœ‰æ•ˆåŒºåŸŸ"""
        # åˆ›å»ºmaskå®šä½æœ‰æ•ˆåŒºåŸŸ
        mask = volume > 0.1
        coords = np.where(mask)
        min_z, max_z = np.min(coords[0]), np.max(coords[0])
        min_y, max_y = np.min(coords[1]), np.max(coords[1])
        min_x, max_x = np.min(coords[2]), np.max(coords[2])
        
        # æ‰©å±•è¾¹ç•Œ
        min_z = max(0, min_z - self.crop_margin)
        max_z = min(volume.shape[0], max_z + self.crop_margin)
        min_y = max(0, min_y - self.crop_margin)
        max_y = min(volume.shape[1], max_y + self.crop_margin)
        min_x = max(0, min_x - self.crop_margin)
        max_x = min(volume.shape[2], max_x + self.crop_margin)
        
        return volume[min_z:max_z, min_y:max_y, min_x:max_x]

    def _resample_volume(self, volume, order=3):
        """å„å‘åŒæ€§é‡é‡‡æ ·"""
        # è®¡ç®—ç¼©æ”¾å› å­
        # zoom_factor = [t/s for t, s in zip(self.target_size, volume.shape)]

        # æ·»åŠ ç»´åº¦éªŒè¯
        assert len(volume.shape) == 3, "è¾“å…¥å¿…é¡»ä¸º3Dæ•°ç»„"

        # ä½¿ç”¨æ ·æ¡æ’å€¼
        resized = resize(
            volume, 
            (self.target_size[0], self.target_size[1], self.target_size[2]), # Z, Y, X
            order=order, 
            mode='constant', 
            cval=0, 
            anti_aliasing=True
        )
        # return resized
        return resized.astype(np.float32)  # ğŸ“ æ·»åŠ æ•°æ®ç±»å‹è½¬æ¢

    def _process_single_case(self, case_id):
        """å¤„ç†å•ä¸ªç—…ä¾‹"""
        try:
            # ================= 1. æ•°æ®åŠ è½½ =================
            # åŠ è½½åŸå§‹CBCTå›¾åƒå’Œæ ‡ç­¾
            volume, affine = self._load_volume(case_id)  # [H, W, D] (NIFTIé»˜è®¤é¡ºåº)
            label = self._load_label(case_id)            # [H, W, D]

            # ================= 2. å›¾åƒé¢„å¤„ç† =================
            # CTå›¾åƒæ ‡å‡†åŒ–
            volume = self._ct_normalization(volume)      # [H, W, D]
            # åŠ¨æ€è£å‰ªæœ‰æ•ˆåŒºåŸŸ
            volume = self._dynamic_crop(volume)          # [H', W', D']
            label = self._dynamic_crop(label)            # [H', W', D']

            # ================= 3. é‡é‡‡æ ·å¤„ç† =================
            # å„å‘åŒæ€§é‡é‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
            volume = self._resample_volume(volume)       # [H=160, W=320, D=320]
            label = self._resample_volume(label, order=0) # [H=160, W=320, D=320]

            # ================= 4. ç»´åº¦é¡ºåºè°ƒæ•´ =================
            # è°ƒæ•´åˆ°MONAIæ ‡å‡†é¡ºåº (D, H, W) -> (C=1, H, W, D)
            volume = np.transpose(volume, (0, 1, 2))     # [D=160, H=320, W=320]
            volume = volume[np.newaxis, ...]             # [C=1, D=160, H=320, W=320]
            
            label = np.transpose(label, (0, 1, 2))       # [D=160, H=320, W=320]

            # ================= 5. æ–¹å‘æ ‡å‡†åŒ– =================
            # è½¬æ¢ä¸ºMetaTensorå¹¶è°ƒæ•´æ–¹å‘
            volume_tensor = MetaTensor(volume, affine=affine)  # æ·»åŠ é€šé“ç»´åº¦
            volume_tensor = Orientation(axcodes="RAS")(volume_tensor)
            # ç§»é™¤Metaä¿¡æ¯å¹¶è½¬æ¢å›numpy
            volume_np = EnsureType(data_type="numpy", track_meta=False)(volume_tensor)
            # volume_tensor = EnsureType()(volume_tensor).array.squeeze(0)

            # ================= 6. æœ€ç»ˆéªŒè¯ =================
            # ç»´åº¦éªŒè¯
            assert volume_np.shape == (1, 160, 320, 320), \
                f"å›¾åƒå°ºå¯¸é”™è¯¯: {volume_np.shape} åº” (1,160,320,320)"
            assert label.shape == (160, 320, 320), \
                f"æ ‡ç­¾å°ºå¯¸é”™è¯¯: {label.shape} åº” (160,320,320)"
            
            # æ•°æ®ç±»å‹éªŒè¯
            assert volume_np.dtype == np.float32, "å›¾åƒå¿…é¡»ä¸ºfloat32"
            assert label.dtype == np.float32, "æ ‡ç­¾å¿…é¡»ä¸ºfloat32"

            # ================= 7. ä¿å­˜æ•°æ® =================
            # ä¿å­˜å¤„ç†ç»“æœ
            save_path = os.path.join(self.save_dir, case_id)
            os.makedirs(save_path, exist_ok=True)
            
            torch.save({
                'volume': torch.FloatTensor(volume_tensor),  # [C=1, D=160, H=320, W=320]
                'label': torch.LongTensor(label),            # [D=160, H=320, W=320] 
                'affine': affine,                            # åŸå§‹ç©ºé—´ä¿¡æ¯
                'spacing': (1.0, 1.0, 1.0)                   # å„å‘åŒæ€§spacing
            }, os.path.join(save_path, f"{case_id}.pt"))

        except Exception as e:
            print(f"Error processing {case_id}: {str(e)}")

    def run(self, num_workers=4):
        """å¯åŠ¨å¹¶è¡Œå¤„ç†"""
        os.makedirs(self.save_dir, exist_ok=True)
        Parallel(n_jobs=num_workers)(
            delayed(self._process_single_case)(case_id)
            for case_id in tqdm(self.case_ids, desc="Processing CBCT")
        )

if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    preprocessor = CBCTPreprocessor(
        root_dir=r"D:\Ashen\Desktop\CBCT_Project\SegFormer3D\data\toothfairy_seg\toothfairy_raw_data\train",
        save_dir=r"D:\Ashen\Desktop\CBCT_Project\SegFormer3D\data\toothfairy_seg\ToothFairy_Training_Data",
        target_size=(160, 320, 320)  # åŒ¹é…Segformer3Dè¾“å…¥å°ºå¯¸
    )
    preprocessor.run(num_workers=1)